{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import date, timedelta\n",
    "from pickle import dump, load\n",
    "import calendar\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "STOCK_INDEX_FILES = ['data/DJIA.csv', 'data/NASDAQCOM.csv', 'data/SP500.csv']\n",
    "\n",
    "# Labels\n",
    "NO_CURRENT_VALUE = 'No current value'\n",
    "NO_NEXT_VALUE = 'No next value'\n",
    "UP = 'Up'\n",
    "DOWN = 'Down'\n",
    "\n",
    "def generate_date_dicts():\n",
    "    for name in STOCK_INDEX_FILES:\n",
    "        with open(name, 'r') as f:\n",
    "            date_dict = {}\n",
    "            reader = csv.reader(f)\n",
    "            reader.__next__() # get rid of header\n",
    "            for row in reader:\n",
    "                if row[1] == '.': # no entry in stock file\n",
    "                    continue\n",
    "                d = date(*list(map(int, row[0].split('-')))) # format date into datetime object\n",
    "                value = float(row[1])\n",
    "                date_dict[d] = value\n",
    "\n",
    "        with open(name.replace('.csv', NAME_EXTENSION), 'wb') as f:\n",
    "            dump(date_dict, f, protocol=2)\n",
    "\n",
    "\n",
    "def get_date_dict(path):\n",
    "    date_dict = {}\n",
    "    with open(path, 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            reader.__next__() # get rid of header\n",
    "            for row in reader:\n",
    "                if row[1] == '.': # no entry in stock file\n",
    "                    continue\n",
    "                d = date(*list(map(int, row[0].split('-')))) # format date into datetime object\n",
    "                value = float(row[1])\n",
    "                date_dict[d] = value\n",
    "    return date_dict\n",
    "\n",
    "def get_date_window(date_dict, center_date, window_size=4):\n",
    "    values = []\n",
    "    i = 0\n",
    "    while len(values) < window_size:\n",
    "        time_delta = timedelta(days=i, seconds=0, microseconds=0, milliseconds=0, minutes=0, hours=0, weeks=0)\n",
    "        d = center_date - time_delta\n",
    "        if d in date_dict:\n",
    "            values.append(date_dict[d])\n",
    "        i += 1\n",
    "    values.reverse()\n",
    "    return values\n",
    "\n",
    "def get_next_date_value(date_dict, center_date):\n",
    "    time_delta = timedelta(days=1, seconds=0, microseconds=0, milliseconds=0, minutes=0, hours=0, weeks=0)\n",
    "    d = center_date + time_delta\n",
    "    if d not in date_dict:\n",
    "        return None\n",
    "    return date_dict[d]\n",
    "\n",
    "def get_wh_data():\n",
    "    month_to_int = {name: num for num, name in enumerate(calendar.month_name) if num}\n",
    "    dates = []\n",
    "    titles = []\n",
    "    bodies = []\n",
    "    with open('data/WH_posts.csv', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        reader.__next__()\n",
    "        for row in reader:\n",
    "            d = row[0].replace(',','').split()\n",
    "            d = date(*[int(d[2]), month_to_int[d[0]], int(d[1])])\n",
    "            dates.append(d)\n",
    "            titles.append(row[1])\n",
    "            bodies.append(row[2])\n",
    "\n",
    "    data = {'dates':dates, 'titles':titles, 'bodies':bodies}\n",
    "    with open('data/WH_posts_structured', 'wb') as f:\n",
    "        dump(data, f, protocol=2)\n",
    "        \n",
    "    return dates, titles, bodies\n",
    "\n",
    "\n",
    "def generate_labels(date_dict, wh_dates):\n",
    "    labels = []\n",
    "    for d in wh_dates:\n",
    "        if d in test_dict:\n",
    "            cur_value = date_dict[d]\n",
    "        else:\n",
    "            labels.append(NO_CURRENT_VALUE)\n",
    "            continue\n",
    "\n",
    "        next_value = get_next_date_value(test_dict, d)\n",
    "        if next_value:\n",
    "            labels.append(UP if (next_value - cur_value) >= 0 else DOWN)\n",
    "        else:\n",
    "            labels.append(NO_NEXT_VALUE)\n",
    "    return labels\n",
    "\n",
    "def filter_labels(labels):\n",
    "    labels = np.array(labels)\n",
    "    labels = labels[np.where(labels != NO_CURRENT_VALUE)[0]]\n",
    "    labels = labels[np.where(labels != NO_NEXT_VALUE)[0]]\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generate_wh_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we want to handle labeling? Do we want to average the three indexes together or generate 3 different labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wh_dates, wh_titles, wh_bodies = get_wh_data()\n",
    "dj_dict = get_date_dict('data/DJIA.csv')\n",
    "nd_dict = get_date_dict('data/NASDAQCOM.csv')\n",
    "sp_dict = get_date_dict('data/SP500.csv')\n",
    "\n",
    "dj_labels = filter_labels(generate_labels(dj_dict, wh_dates))\n",
    "nd_labels = filter_labels(generate_labels(nd_dict, wh_dates))\n",
    "sp_labels = filter_labels(generate_labels(sp_dict, wh_dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 340 labels total\n",
      "No label: 0\n",
      "There are 340 positive labels\n",
      "169\n",
      "169\n",
      "0\n",
      "['Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down'\n",
      " 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down'\n",
      " 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down'\n",
      " 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down'\n",
      " 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down'\n",
      " 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down'\n",
      " 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down'\n",
      " 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down'\n",
      " 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down'\n",
      " 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down'\n",
      " 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down'\n",
      " 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down'\n",
      " 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down'\n",
      " 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down'\n",
      " 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down'\n",
      " 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down'\n",
      " 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down' 'Down']\n",
      "['Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up'\n",
      " 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up'\n",
      " 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up'\n",
      " 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up'\n",
      " 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up'\n",
      " 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up'\n",
      " 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up'\n",
      " 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up'\n",
      " 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up'\n",
      " 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up'\n",
      " 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up' 'Up'\n",
      " 'Up' 'Up' 'Up' 'Up']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"There are %d labels total\" %len(dj_labels))\n",
    "print(\"No label: %d\" % (len(np.where(dj_labels == NO_CURRENT_VALUE)[0]) + len(np.where(dj_labels == NO_NEXT_VALUE)[0])))\n",
    "print(\"There are %d positive labels\" % (499-159))\n",
    "\n",
    "index_differences = np.where(dj_labels != nd_labels)[0]\n",
    "print(len(np.where(dj_labels != nd_labels)[0]))\n",
    "print(len(np.where(dj_labels != sp_labels)[0]))\n",
    "print(len(np.where(nd_labels != sp_labels)[0]))\n",
    "print(dj_labels[index_differences])\n",
    "print(sp_labels[index_differences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
